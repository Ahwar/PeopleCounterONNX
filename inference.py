import onnxruntime as nxrun
import numpy as np
import cv2


class Network:
    def load_model(self, model_path) -> None:
        """
        Load the ONNX model form path in ONNX Session
        """

        # define the priority order for the execution providers
        # prefer CUDA Execution Provider over CPU Execution Provider
        providers = ["CUDAExecutionProvider", "CPUExecutionProvider"]
        ## start inference session
        self.sess = nxrun.InferenceSession(model_path, providers=providers)

        ## input, output shape
        self.input_name = self.sess.get_inputs()[0].name
        self.output_name = self.sess.get_outputs()[0].name
        self.input_shape = self.sess.get_inputs()[0].shape
        self.outname = [i.name for i in self.sess.get_outputs()]

    def inference(self, input, output_name=None):
        """
        Do ONNXruntime inference on input numpy array
        """
        ## run onnx model with onnx runtime python
        result = self.sess.run(
            self.outname, {self.input_name: input.astype(np.float32)}
        )[0]
        result = np.array(result).astype(np.float32)
        return result

    def apply_threshold(
        self,
        frame,
        detections,
        required_classes,
        input_width,
        input_height,
        class_names,
    ):
        """
        take frame and model detection and draw bounding boxes around
        detected objects

        Parameters:
            frame: the image frame from the input stream
            detections: the output generated by the model
            required_classes: define which classes you want to filter
            input_width: the width of input required by the model
            input_height: the height of input required by the model
            class_names: the labels of classes
        Returns:
            frame
        """
        processed_frame = frame
        # input frame information
        frame_w, frame_h = frame.shape[1], frame.shape[0]
        current_people_count = 0  # people count variable
        for x0, y0, x1, y1, score, cls_id in detections[0]:
            # filter only required classes
            if cls_id in required_classes:
                ### draw bounding box around person
                # convert the explicit box point to ratio according to model input
                x0, y0 = x0 / input_width, y0 / input_height
                x1, y1 = x1 / input_width, y1 / input_height

                # convert ratio to pixels points according the frame shape
                start_point = (
                    int(x0 * frame_w),
                    int(y0 * frame_h),
                )  # start point of the rectangle
                end_point = (
                    int(x1 * frame_w),
                    int(y1 * frame_h),
                )  # start point of the rectangle
                score = round(float(score), 3)
                label = class_names[int(cls_id)]
                label += " " + str(score)
                # draw rectangle
                processed_frame = cv2.rectangle(
                    processed_frame, start_point, end_point, (13, 255, 0), 2
                )

                # put detected object's labels
                cv2.putText(
                    processed_frame,
                    label,
                    start_point,
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.75,
                    (13, 255, 0),
                    thickness=2,
                )
                # if object is a person
                if cls_id == 0:
                    current_people_count += 1
        return processed_frame, current_people_count
